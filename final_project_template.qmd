---
title: "Genetic and Environmental Factors Shaping Height and Weight: A Study of Twins and Adoption"
subtitle: "BMIN503/EPID600 Final Project"
author: "ZI WANG"
format: html
editor: visual
number-sections: true
embed-resources: true
---

------------------------------------------------------------------------

## Overview {#sec-overview}

Studying both biological and virtual twins can provide comprehensive insights into the influences of genetics and environment. Biological twins help emphasize the impact of genetic factors, whereas virtual twins highlight the role of shared early-life environmental factors. The main objective of this twin study is to distinguish the contribution of nature in influencing height and weight, as opposed to nurture."

## Introduction {#sec-introduction}

There is no doubt that genetic and environmental factors significantly impact early childhood growth and development. Complex interactions and correlations exist among genetic, prenatal environmental, and postnatal environmental influences, leading to a range of health-related outcomes. However, much debate has concerned the dominant influence of nature or nurture. Twin and adoption studies have been widely employed by researchers to assess differences within study pairs and estimate the contributions of genetic and environmental factors to various traits and behaviors. In this study, we aim to evaluate whether genetics or the shared environment significantly influences the variations in height and weight among pairs of twins, siblings, and adoptees.

When we dive into the study of height and weight in twins and adoptees, genes certainly lay the groundwork, but where and how a child is raised also play a crucial role of their early growth and development. This complex question requires insights from various fields. 
In the scientific area, geneticists start searching for the specific genes that affect height and weight the most. Meanwhile, nutrition experts bring in their expertise to exploring how their diets shape these physical characteristics. Epidemiologists shift their concerns to figure out how common certain height and weight traits are and what factors are more likely to contribute to these differences, while biostatisticians step into analyzing datasets and quantifying the relative contributions of genetics and environment to variations in individual characteristics.
These fields will share their own piece to the puzzle to understanding the interfaces of nature and nurture in children’s early years of growth and development.

## Methods {#sec-methods}

Describe the data used and general methodological approach used to address the problem described in the @sec-introduction. Subsequently, incorporate full R code necessary to retrieve and clean data, and perform analysis. Be sure to include a description of code so that others (including your future self) can understand what you are doing and why.

Twin studies are useful to disentangle the relative importance of environmental and genetic influences on individual traits and behaviors. Two types of twins can be included in these studies: biological and virtual twins. Biological twins include monozygotic (MZ) twins and dizygotic (DZ) twins. MZ twins are developed from the same zygote and thus have the same genetic components. Dizygotic (DZ) twins are developed from two different zygotes and like any other siblings, share in average 50% of their genetic variants. Virtual twins (VTs) are two adoptees or one natural child plus one adoptee who are of the same age and are raised together since infancy. VT twins do not have much of the genes in common. All MZ, DZ and VT twins share many aspects of their environment. Thus, MZ twins are almost always more similar than DZ twins due to higher genetic similarity coupled with the same amount of environmental similarity, while DZ twins share more similarity than VT twins. By comparing the similarity of MZ, DZ, and VT twins, we can decompose the roles of genetic and environmental factors on traits of interest.
The goal of this twin study was to understand whether the genetic or environmental factors influence height and weight more. The data “twin.txt” included 1098 individuals from 168 monozygotic (MZ) twin pairs, 169 dizygotic (DZ) twin pairs, 139 virtual twin (VT) pairs.

### 1. Data Exploration
#### 1.1 Load the necessary R packages:

```{r}
library(dplyr)
library(epiDisplay)
library(tidyverse)
library(ggplot2)
library(vtable)
library(mice)
library(missForest)
library(grid)
library(gridExtra)
library(cowplot)
library(gtsummary)
library(nlme)
library(rstatix)
library(hrbrthemes)

# Function for corr test & plot
corrplot2 <- function(data,
                      method = "pearson",
                      sig.level = 0.05,
                      order = "original",
                      diag = FALSE,
                      type = "upper",
                      tl.srt = 90,
                      number.font = 1,
                      number.cex = 1,
                      mar = c(0, 0, 0, 0)) {
  library(corrplot)
  data_incomplete <- data
  data <- data[complete.cases(data), ]
  mat <- cor(data, method = method)
  cor.mtest <- function(mat, method) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat <- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
      for (j in (i + 1):n) {
        tmp <- cor.test(mat[, i], mat[, j], method = method)
        p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
      }
    }
    colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
    p.mat
  }
  p.mat <- cor.mtest(data, method = method)
  col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
  corrplot(mat,
           method = "color", col = col(200), number.font = number.font,
           mar = mar, number.cex = number.cex,
           type = type, order = order,
           addCoef.col = "black", # add correlation coefficient
           tl.col = "black", tl.srt = tl.srt, # rotation of text labels
           # combine with significance level
           p.mat = p.mat, sig.level = sig.level, insig = "blank",
           # hide correlation coefficients on the diagonal
           diag = diag
  )
}

```

#### 1.2 Load and explore the dataset:
```{r}
## read in dataset
#list.files("/Users/ziwang89/dropbox/penn_phd/BMIN503:EPID600_2023FALL/final project/")
Twin_dat <- read.table("/Users/ziwang89/dropbox/penn_phd/BMIN503:EPID600_2023FALL/final project/Data_Twin_Study.txt", header = T, sep = "")

#check the dim of the twin data set
dim(Twin_dat)

#list the length of unique twin pairs based on ID number (IDNO)
length(unique(Twin_dat$IDNO))

#check whether there exists pairs of triple twins babies or cases of mislabeling
Twin_dat %>% count(IDNO) %>% filter( n != 2 )

#generate a table of Birth Order 
table(Twin_dat$BO)
#access the row with a wrong Birth Order label
Twin_dat %>% group_by(IDNO) %>% count(BO) %>% filter( n != 1 )
(Twin_dat[Twin_dat$IDNO == 467,])
Twin_dat[917,]

#correct the wrong Birth Order label
Twin_dat$BO[917] = 1
#check the correction
(Twin_dat[Twin_dat$IDNO == 467,])

#pre-view the data set
head(Twin_dat,10)
```

By digging into the data set, we see that there is information overlap between variables. There are two rows of each study pair, and the variable **BO** indicates the Birth Order. However, in the column of the variable **HT1**, it not only lists the height of child 1 as defined but also includes the height of child 2 in the second row of each pair, same as the column of the variable **WT1**. Thus, we can regenerate our outcomes as below.

```{r}
# check the distribution of the main outcomes
summary(Twin_dat$HT1[Twin_dat$BO==2])
length(Twin_dat$HT1[Twin_dat$BO==2])
summary(Twin_dat$HT2[Twin_dat$BO==1])
length(Twin_dat$HT2[Twin_dat$BO==1])

# check if two cells of the same pair have a one-to-one relationship
Twin_dat <- Twin_dat |> group_by(IDNO) |> mutate(check.HT = ifelse( HT1[BO==2] == HT2[BO==1],1,0 ),
                                                 check.WT = ifelse( WT1[BO==2] == WT2[BO==1],1,0 )) 


Twin_dat |> filter(check.HT==0 | check.WT==0)

# combine the information of four potential outcomes to create new accurate outcomes for each pair

Twin_dat <- Twin_dat |> group_by(IDNO) |> mutate(
  HT = case_when(
    BO == 1 ~ HT1[BO==1],
    BO == 2 ~ HT2[BO==1]
  ),
   WT = case_when(
    BO == 1 ~ WT1[BO==1],
    BO == 2 ~ WT2[BO==1]
  ),
)

# check the new outcomes
head(Twin_dat[,c("IDNO","BO","HT1","HT2","HT",
                    "WT1","WT2","WT")])

# pull a new sub data set for further analysis
names(Twin_dat)
TwinData <- Twin_dat |> dplyr::select(IDNO,BO,Zyg,Sex,Race,
                                      AgeMon,BWOZ,BirLenth,
                                      HT,WT)

```


### 2. Descriptive Analysis
#### 2.1 Descriptive statistics of the raw data set:
```{r}
## to change data type based on given variables 
names(TwinData)

TwinData$BO <- factor(TwinData$BO,levels = c(1,2))
TwinData$Zyg <- factor(TwinData$Zyg,levels = c(1,2,3,4,5))
TwinData$Sex <- factor(TwinData$Sex,levels = c(1,2))
TwinData$Race <- factor(TwinData$Race,levels = c(1,2,3,4,5,6,7,8,9,0))

# Create two new age related variables using AgeMon: Age by year, Lifespan Stages
TwinData <- TwinData |> mutate(AgeYEAR = round(AgeMon/12,2),
                                  LifespanStages = case_when(
                                    AgeYEAR < 2 ~ "Infancy",
                                    AgeYEAR >=2 & AgeYEAR < 12 ~ "Childhood",
                                    AgeYEAR >=12 & AgeYEAR < 18 ~ "Adolescence",
                                    AgeYEAR >=18  ~ "Adulthood"
                                  ))

TwinData$LifespanStages <- factor(TwinData$LifespanStages, levels = c("Infancy","Childhood","Adolescence","Adulthood"))
TwinData$AgeMon <- as.numeric(TwinData$AgeMon )

## to generate a descriptive statistics table of the raw twins dataset by birth order
TwinData |> tbl_summary(by = BO) |>
  add_p()

```

#### 2.2 Descriptive statistics of missing values:
```{r}
## to count the number of missingness for each variables contained missingness
### for main outcomes
length(TwinData$IDNO[TwinData$HT==99.99]) #7
length(TwinData$IDNO[TwinData$WT==999.99]) #29


### for main predictors 
##### **BWOZ** Birth Weight in ounces Missing = 999.00
length(TwinData$IDNO[TwinData$BWOZ==999.00]) #413
##### **BirLenth** Birth Length in inches Missing = 99.90
length(TwinData$IDNO[TwinData$BirLenth==99.90]) #494
##### race
length(TwinData$IDNO[TwinData$Race==0]) #6

length(TwinData$IDNO[TwinData$BirLenth==99.90 & TwinData$BWOZ==999.00]) #413

## to generate a sub data set stored information of all subjects with missing both main predictors
Twin_missBirthInfo <- TwinData |> filter( BWOZ == 999.00 &
                                      BirLenth == 99.90 )

dim(Twin_missBirthInfo)
#413
```

#### 2.3 Preliminary Data visualization:

##### for categorical variables

According to the Data Dictionary,
**Zyg** (Zygosity): 1=MZ 2=DZ 3=VT (2 adoptees) 4=VT (1 adoptee, 1 biological child) 5=Full sibs

**Sex** 1 = Female, 2 = Male

**Race** 1=African-American, 2=American Indian/Alaska Native 3=Asian 4=Native Hawaiian/pacific Islander 5=White 6=Hispanic 7=South American Indian 8 = Mixed 9 = Other 0 = Missing
```{r}
## to generate a sub data set filtered by data quality of height and weight at birth
Twin_subdat <- TwinData |> filter(!(IDNO %in% Twin_missBirthInfo$IDNO)) |> group_by(IDNO) |> filter(n()==2)

dim(Twin_subdat)
length(unique(Twin_subdat$IDNO)) # 341 pairs -- 682 subjects

# to compare the distribution for Zygosity groups. 
# the frequency table of Zygosity Groups
### for the full data set
tab1(TwinData$Zyg,
  main="Distribution of Zygosity Groups in full data set")
### for the sub data set
tab1(Twin_subdat$Zyg,
  main="Distribution of Zygosity Groups in sub data set")

# to compare the distribution of race groups. 
### for the full data set
tab1(TwinData$Race,
  main="Distribution of Race Groups in full data set")
### for the sub data set
tab1(Twin_subdat$Race,
  main="Distribution of Race Groups in sub data set")
```

Accordingly, there are 413 subjects who are missing both birth weight and birth length in the raw data set. That is 37.6% of our study cohort. 
Considering the missing proportion of predictor variables, our primary endpoint will be the height and weight variation among all biological and virtual twins; whereas, our primary endpoint will be the height and weight variation for biological twins only. Additionally, the data is very skewed based on race categories.  


### 3. Primary Analysis 
#### 3.1 Data Preparation 

There isn't much information we could gather from the height and weight at birth for virtual twins due to high proportions of missing values. Thus, we will exclude the two variables **BWOZ** and **BirLenth** from our primary analysis. We will apply data imputation methods for the rest variables.

Accordingly,
**Ht1** (Height of child 1 in inches) Missing Values = 99.99
**Wt1** (Weight of child 1 in pounds Missing Values = 999.99
**Ht2** (Height of child 2 in inches) Missing Values = 99.99
**Wt2** (Weight of child2 in pounds Missing Values = 999.99
**Race** 1 = African-American, 2 = American Indian/Alaska Native, 3 = Asian, 4 = Native, Hawaiian/pacific Islander, 5 = White, 6 = Hispanic, 7 = South American Indian, 8 = Mixed, 9 = Other, 0 = Missing

```{r}
names(TwinData)
#View(Twin_dat)
dim(TwinData)

## to create new variables for further analysis and missing imputation
primary_dat <- TwinData |> mutate(## variables created below are for missing imputation
                               HT_imp = if_else(HT != 99.99,HT, NA_integer_),
                               WT_imp = if_else(WT != 999.99,WT,NA_integer_)) |> as.data.frame()
#dim(primary_dat)
summary(primary_dat)

primary_dat$HT <- as.numeric(primary_dat$HT)
primary_dat$WT <- as.numeric(primary_dat$WT)
primary_dat$HT_imp <- as.numeric(primary_dat$HT_imp)
primary_dat$WT_imp <- as.numeric(primary_dat$WT_imp)


imput_numeric <- primary_dat %>%
  select(HT_imp, WT_imp, AgeMon, Zyg, Sex,Race)

## to impute missing values using missForest & laso.norm: Lasso linear regression.
imput_numeric <- imput_numeric |> ungroup() |> dplyr::mutate(
  HT_missForest = missForest(imput_numeric)$ximp$HT_imp,
  WT_missForest = missForest(imput_numeric)$ximp$WT_imp,
  HT_lasso = complete(mice(imput_numeric, method = "lasso.norm"))$HT_imp,
  WT_lasso = complete(mice(imput_numeric, method = "lasso.norm"))$WT_imp
)

summary(imput_numeric)

####### Height
HT.P <- ggplot(imput_numeric, aes(x = HT_imp)) +
  geom_histogram(fill = "#ad1538", color = "#000000", position = "identity") +
  labs(x ="Height (inches)") + 
  ggtitle("Original Distribution of Height") +
  theme_classic()

HTimp.missForest <- ggplot(imput_numeric, aes(x = HT_missForest)) +
  geom_histogram(fill = "#1543ad", color = "#000000", position = "identity") +
  labs(x ="Height (inches)") + 
  ggtitle("MissForest-imputed Distribution of Height") +
  theme_classic()

HTimp.lasso <- ggplot(imput_numeric, aes(x = HT_lasso)) +
  geom_histogram(fill = "#1543ad", color = "#000000", position = "identity") +
  labs(x ="Height (inches)") + 
  ggtitle("Lasso-imputed Distribution of Height") +
  theme_classic()

####### Weight
WT.P <- ggplot(imput_numeric, aes(x = WT_imp)) +
  geom_histogram(fill = "#ad1538", color = "#000000", position = "identity") +
  labs(x ="Weight (pounds)") +
  ggtitle("Original Distribution of Weight") +
  theme_classic()

WTimp.missForest <- ggplot(imput_numeric, aes(x = WT_missForest)) +
  geom_histogram(fill = "#1543ad", color = "#000000", position = "identity") +
  labs(x ="Weight (pounds)") +
  ggtitle("MissForest-imputed Distribution of Weight") +
  theme_classic()

WTimp.lasso <- ggplot(imput_numeric, aes(x = WT_lasso)) +
  geom_histogram(fill = "#1543ad", color = "#000000", position = "identity") +
  labs(x ="Weight (pounds)") +
  ggtitle("Lasso-imputed Distribution of Weight") +
  theme_classic()


plot_grid(HT.P, WT.P,
          HTimp.missForest,WTimp.missForest,
          HTimp.lasso,WTimp.lasso,
          nrow = 3, ncol = 2)

# to generate a descriptive statistics table of the raw twins dataset
imput_numeric |> dplyr::select(HT_imp,HT_missForest,HT_lasso,
                             WT_imp,WT_missForest,WT_lasso) |> tbl_summary()

# final primary outcomes
primary_dat$HT_lasso <- imput_numeric$HT_lasso
primary_dat$WT_lasso <- imput_numeric$WT_lasso
```

The Miss Forest imputation technique is based on the Random Forest algorithm. As a non-parametric imputation method, it estimates the function in a way that’s closest to the data points without any assumptions about the function form. On the other hand, MICE stands for Multivariate Imputation via Chained Equations, and it’s one of the most common packages for R users. Lasso linear regression method from mice package is applied here.Take a look at the variable distribution changes by summary table and a grid of histograms, we know the imputed variables are in a good shape. The imputed distributions overall look much closer to the original one. The lasso-imputed height and weight distributions look the closest. 
Next, we will construct the univariate and multivariate analyses.

#### 3.2 Primary Data Visualization

First of all, let's visualize the distribution for each Zygosity subgroup by gender. 
```{r}
primary_dat |> dplyr::select(Zyg,Sex) |> tbl_summary(by = Sex) |> add_overall() |> add_n() |> bold_labels()


# proportions in Zygosity groups by Gender 
ggplot(primary_dat,aes(x = Zyg, y = ..prop.., fill =Sex, group = Sex)) +
  geom_bar() +
  geom_label(aes(label = ..count..), position = position_stack(vjust = 0.5), 
             stat = "count", 
            colour = "white")+
  scale_fill_discrete(name = "Sex", labels = c("Female", "Male")) +
  scale_x_discrete(name="Zygosity",
                   labels=c("1" = "1\nMonozygotic", "2" = "2\nDizygotic", "3" = "3\nTwo Adoptees",
                            "4"="4\n1 Adoptee, \n1 Biological Child","5"="5\nTwo Siblings"))  +
  scale_y_continuous(labels = scales::percent) +
    theme_ipsum() 


# proportions in Zygosity groups by Gender 
ggplot(primary_dat, aes(fill=Sex, y = ..prop.., x=Zyg)) + 
    #geom_bar(position="stack", stat="identity") +
    geom_bar(aes( y=..count../tapply(..count.., ..x.. ,sum)[..x..]), position="dodge" ) +
    geom_text(aes( y=..count../tapply(..count.., ..x.. ,sum)[..x..], label=scales::percent(..count../tapply(..count.., ..x.. ,sum)[..x..]) ),
            stat="count", position=position_dodge(0.9), vjust=-0.5)+
    ylab('Percent of Gender Group, %') +
  scale_fill_discrete(name = "Sex", labels = c("Female", "Male")) +
  scale_x_discrete(name="Zygosity",
                   labels=c("1" = "1\nMonozygotic", "2" = "2\nDizygotic", "3" = "3\nTwo Adoptees",
                            "4"="4\n1 Adoptee, \n1 Biological Child","5"="5\nTwo Siblings"))  +
  scale_y_continuous(labels = scales::percent) +
    theme_classic()


```


##### for outcomes

```{r}
####################################
### for Height of child 1 in inches
####################################
# Normal curve
fun <- dnorm(primary_dat$HT_lasso[primary_dat$BO == 1], mean = mean(primary_dat$HT_lasso[primary_dat$BO == 1]), 
             sd = sd(primary_dat$HT_lasso[primary_dat$BO == 1]))
max(fun)

par(mfrow = c(1, 1))
# Histogram
hist(primary_dat$HT_lasso[primary_dat$BO == 1], 
     probability = TRUE, xlab = expression("Height"[1]*"(inches)"), col = "grey", #ylim = c(0, max(fun)+0.01),
     axes = FALSE, 
     main =  expression("Distribution of Height of Child 1"))
# Axis
axis(1)
# Density
lines(density(primary_dat$HT_lasso[primary_dat$BO == 1]), col = "red", lwd = 2)
# Add boxplot
par(new =TRUE)
boxplot(primary_dat$HT_lasso[primary_dat$BO == 1], horizontal = TRUE, 
        axes = FALSE, 
        #ylim = c(-20,65),
        boxlwd = 1, outwex = 0.5, boxwex = 0.2,
        lwd = 2, col = rgb(0, 1, 1, alpha = 0.15)
)
stripchart(primary_dat$HT_lasso[primary_dat$BO == 1],              # Data
           #method = "jitter", # Random noise
           pch = 18,          # Pch symbols
           col = 4,           # Color of the symbol
           # vertical = TRUE,   # Vertical mode
           add = TRUE) 

####################################
### for Weight of child 1 in pounds
####################################
# Normal curve
fun <- dnorm(primary_dat$WT_lasso[primary_dat$BO == 1], mean = mean(primary_dat$WT_lasso[primary_dat$BO == 1]), sd = sd(primary_dat$WT_lasso[primary_dat$BO == 1]))
max(fun)

par(mfrow = c(1, 1))
# Histogram
hist(primary_dat$WT_lasso[primary_dat$BO == 1], probability = TRUE, xlab = expression("Weight"[1]*"(pounds)"), col = "grey", #ylim = c(0, max(fun)+0.01),
     axes = FALSE, 
     main =  expression("Distribution of Weight of Child 1"))
# Axis
axis(1)
# Density
lines(density(primary_dat$WT_lasso[primary_dat$BO == 1]), col = "red", lwd = 2)
# Add boxplot
par(new =TRUE)
boxplot(primary_dat$WT_lasso[primary_dat$BO == 1], horizontal = TRUE, 
        axes = FALSE, 
        #ylim = c(-20,65),
        boxlwd = 1, outwex = 0.5, boxwex = 0.2,
        lwd = 2, col = rgb(0, 1, 1, alpha = 0.15)
)
stripchart(primary_dat$WT_lasso[primary_dat$BO == 1],              # Data
           #method = "jitter", # Random noise
           pch = 18,          # Pch symbols
           col = 4,           # Color of the symbol
           # vertical = TRUE,   # Vertical mode
           add = TRUE) 

####################################
### for Height of child 2 in inches
####################################
# Normal curve
fun <- dnorm(primary_dat$HT_lasso[primary_dat$BO == 2], mean = mean(primary_dat$HT_lasso[primary_dat$BO == 2]), sd = sd(primary_dat$HT_lasso[primary_dat$BO == 2]))
max(fun)

par(mfrow = c(1, 1))
# Histogram
hist(primary_dat$HT_lasso[primary_dat$BO == 2], probability = TRUE, xlab = expression("Height"[2]*"(inches)"), col = "grey", #ylim = c(0, max(fun)+0.01),
     axes = FALSE, 
     main =  expression("Distribution of Height of Child 2"))
# Axis
axis(1)
# Density
lines(density(primary_dat$HT_lasso[primary_dat$BO == 2]), col = "red", lwd = 2)
# Add boxplot
par(new =TRUE)
boxplot(primary_dat$HT_lasso[primary_dat$BO == 2], horizontal = TRUE, 
        axes = FALSE, 
        #ylim = c(-20,65),
        boxlwd = 1, outwex = 0.5, boxwex = 0.2,
        lwd = 2, col = rgb(0, 1, 1, alpha = 0.15)
)
stripchart(primary_dat$HT_lasso[primary_dat$BO == 2],              # Data
           #method = "jitter", # Random noise
           pch = 18,          # Pch symbols
           col = 4,           # Color of the symbol
           # vertical = TRUE,   # Vertical mode
           add = TRUE) 

####################################
### for Weight of child 1 in pounds
####################################
# Normal curve
fun <- dnorm(primary_dat$WT_lasso[primary_dat$BO == 2], mean = mean(primary_dat$WT_lasso[primary_dat$BO == 2]), sd = sd(primary_dat$WT_lasso[primary_dat$BO == 2]))
max(fun)

par(mfrow = c(1, 1))
# Histogram
hist(primary_dat$WT_lasso[primary_dat$BO == 2], probability = TRUE, xlab = expression("Weight"[2]*"(pounds)"), col = "grey", ylim = c(0, max(fun)+0.0057),
     axes = FALSE, 
     main =  expression("Distribution of Weight of Child 2"))
# Axis
axis(1)
# Density
lines(density(primary_dat$WT_lasso[primary_dat$BO == 2]), col = "red", lwd = 2)
# Add boxplot
par(new =TRUE)
boxplot(primary_dat$WT_lasso[primary_dat$BO == 2], horizontal = TRUE, 
        axes = FALSE, 
        #ylim = c(-20,65),
        boxlwd = 1, outwex = 0.5, boxwex = 0.2,
        lwd = 2, col = rgb(0, 1, 1, alpha = 0.15)
)
stripchart(primary_dat$WT_lasso[primary_dat$BO == 2],              # Data
           #method = "jitter", # Random noise
           pch = 18,          # Pch symbols
           col = 4,           # Color of the symbol
           # vertical = TRUE,   # Vertical mode
           add = TRUE) 

```
##### 3.3 Univariate analysis
Considering the proportion of the missingness, we will exclude the baseline measurements, birth weight and birth height, from the primary analysis. 
```{r}
## get the variable list for testing
names(primary_dat)
var.list <- colnames(primary_dat)
var.list <- var.list[-c(1,2,7:11,13:16)]

## test the model setting, with or without a random effect 
i=4
mod <- as.formula(sprintf("HT_lasso ~ %s ", var.list[i]))

# compare a model with no random effects to a model with a random effect 
## with a random effect 
mod.RE = lme(mod,method="ML",na.action=na.omit,
    random = ~1 |IDNO,  control = lmeControl(opt = 'optim'),
                 data = primary_dat)
## without  a random effect 
mod = lm(mod,primary_dat)

## AIC test 
bbmle::AICtab(mod.RE,mod) # lower AIC it is considered significantly better than that model.

summary(mod.RE)$tTable 

round(summary(mod.RE)$tTable,3) |> as.data.frame() |> add_column(
  Outcome = noquote("HT_lasso"),
  Varible = noquote(var.list[i]), .before = "Value") |> dplyr::select(-c(`Std.Error`,`DF`,`t-value`)) |>
  dplyr::rename("Estimate" = "Value") |> slice(-1)



######### 
# for loop for table Automation
#########
# create a empty output table to store results
result_tab <- data.frame(V1 = character(),
                         V2 = character(),
                         V3 = numeric(),
                         V4 = numeric())
names(result_tab)[names(result_tab)=='V1']='Outcome'
names(result_tab)[names(result_tab)=='V2']='Varible'
names(result_tab)[names(result_tab)=='V3']='Estimate'
names(result_tab)[names(result_tab)=='V4']='p-Value'
result_tab 


# for loop for outcome HT_lasso
for(i in 1:length(var.list)) {
  # step 1: define model formula
  mod <- as.formula(sprintf("HT_lasso ~ %s ", var.list[i])) # %s would be replaced by the variable name, 
  
  # step 2: run model
  mod.RE = lme(mod,method="ML",na.action=na.omit, 
               random = ~1 |IDNO,  control = lmeControl(opt = 'optim'),data = primary_dat)
  
  # step 3: summarize model result
  fit_result <- round(summary(mod.RE)$tTable,3) |> as.data.frame() |> add_column(
  Outcome = noquote("HT_lasso"),
  Varible = noquote(var.list[i]), .before = "Value") |> dplyr::select(-c(`Std.Error`,`DF`,`t-value`)) |>
  dplyr::rename("Estimate" = "Value") |> slice(-1)

  
  # step 4: append the model result to the final result table
  result_tab  <- rbind(result_tab,fit_result)
}

# for loop for outcome WT_lasso
for(i in 1:length(var.list)) {
  # step 1: define model formula
  mod <- as.formula(sprintf("WT_lasso ~ %s ", var.list[i])) # %s would be replaced by the variable name, 
  
  # step 2: run model
  mod.RE = lme(mod,method="ML",na.action=na.omit, 
               random = ~1 |IDNO,  control = lmeControl(opt = 'optim'),data = primary_dat)
  
  # step 3: summarize model result
  fit_result <- round(summary(mod.RE)$tTable,3) |> as.data.frame() |> add_column(
  Outcome = noquote("WT_lasso"),
  Varible = noquote(var.list[i]), .before = "Value") |> dplyr::select(-c(`Std.Error`,`DF`,`t-value`)) |>
  dplyr::rename("Estimate" = "Value") |> slice(-1)

  
  # step 4: append the model result to the final result table
  result_tab  <- rbind(result_tab,fit_result)
}

# check the final result table
result_tab
View(result_tab)

```

##### 3.4 Multivariate analysis

Model for Height
```{r}
mod.height1 = lme(HT_lasso ~ Zyg + AgeMon  ,method="ML",na.action=na.omit, 
               random = ~1 |IDNO,  control = lmeControl(opt = 'optim'),data = primary_dat)

mod.height2 = lme(HT_lasso ~ Zyg + Sex + AgeMon  ,method="ML",na.action=na.omit, 
               random = ~1 |IDNO,  control = lmeControl(opt = 'optim'),data = primary_dat)
  
round(summary(mod.height1)$tTable,3) 
round(summary(mod.height2)$tTable,3) 

## AIC test 
bbmle::AICtab(mod.height1,mod.height2) 

```

Model for Weight
```{r}
mod.weight1 = lme(WT_lasso ~ Zyg + AgeMon ,method="ML",na.action=na.omit, 
               random = ~1 |IDNO,  control = lmeControl(opt = 'optim'),data = primary_dat)
mod.weight2 = lme(WT_lasso ~ Zyg + Sex + AgeMon ,method="ML",na.action=na.omit, 
               random = ~1 |IDNO,  control = lmeControl(opt = 'optim'),data = primary_dat)
 
round(summary(mod.weight1)$tTable,3) 
round(summary(mod.weight2)$tTable,3) 

## AIC test 
bbmle::AICtab(mod.weight1,mod.weight2) 

```

#### 4. Subgroup Analysis
##### 4.1 Data Preparation and Exploration 

```{r}
#View(Twin_subdat)
###### recall
## to generate a sub data set filtered by data quality of height and weight at birth
#Twin_subdat <- TwinData |> filter(!(IDNO %in% Twin_missBirthInfo$IDNO)) |> group_by(IDNO) |> filter(n()==2)

Twin_subdat |> tbl_summary(by = BO) |> add_overall() |> add_n() |> bold_labels()
Twin_subdat |> dplyr::select(Zyg,BO) |> tbl_summary(by = BO) |> add_overall() |> add_n() |> bold_labels()

## to generate a sub data set including  MZ (monozygotic) & DZ (dizygotic) only
subgrp_data <- Twin_subdat |> filter(Zyg %in% c(1,2)) 


## to create new variables for further analysis and missing imputation
#. **BWOZ** Birth Weight in ounces Missing = 999.00
#. **BirLenth** Birth Length in inches Missing = 99.90

subgrp_data <- subgrp_data |> mutate(## variables created below are for missing imputation
                               HT_na = if_else(HT != 99.99,HT, NA_integer_),
                               WT_na = if_else(WT != 999.99,WT,NA_integer_),
                               BWOZ_na = if_else(BWOZ != 999.00,BWOZ, NA_integer_),
                               BirLenth_na = if_else(BirLenth != 99.90,BirLenth, NA_integer_),) |> as.data.frame()

#dim(primary_dat)
## to create descriptive table for the subgroup data set
subgrp_data |> tbl_summary(by = BO) |> add_overall() |> add_n() |> bold_labels() 


## to create a imputation subset
for_imput <- subgrp_data %>%
  select(HT_na, WT_na, 
         BWOZ_na, BirLenth_na,
         AgeMon,Zyg,Sex,Race)

## to impute missing values of Birth length using laso.norm: Lasso linear regression.
for_imput <- for_imput |> ungroup() |> dplyr::mutate(
  BirLenth_lasso = complete(mice(for_imput, method = "lasso.norm"))$BirLenth_na)


# to generate a descriptive statistics table of the sub dataset
for_imput |> dplyr::select(BirLenth_na,BirLenth_lasso) |> tbl_summary()

# final subgroup predictors
subgrp_data$BirLenth_lasso <- for_imput$BirLenth_lasso

# to revise descriptive table for the subgroup data set
subgrp_data |> tbl_summary(by = BO) |> add_overall() |> add_n() |> bold_labels() 


```

##### 4.2 Subgroup Data Visualization 

```{r}
# proportions in Zygosity groups by Gender 
ggplot(subgrp_data,aes(x = Zyg, y = ..prop.., fill =Sex, group = Sex)) +
  geom_bar() +
  geom_label(aes(label = ..count..), position = position_stack(vjust = 0.5), 
             stat = "count", 
            colour = "white")+
  scale_fill_discrete(name = "Sex", labels = c("Female", "Male")) +
  scale_x_discrete(name="Zygosity",
                   labels=c("1" = "1\nMonozygotic", "2" = "2\nDizygotic", "3" = "3\nTwo Adoptees",
                            "4"="4\n1 Adoptee, \n1 Biological Child","5"="5\nTwo Siblings"))  +
  scale_y_continuous(labels = scales::percent) +
    theme_ipsum() 


# Plot outcome distributions
### by Sex
HT_Sex <- subgrp_data %>%
  ggplot(aes(x = HT_na,
             y = Sex,
             fill = Sex)) +
  ggtitle("Plot of Distribution of Height \nby Sex") +
  xlab("Height (inches)") +
  scale_fill_discrete(name = "Sex", labels = c("Female", "Male")) +
  ggridges::geom_density_ridges(bandwidth = 4) + theme_ipsum() 


WT_Sex <- subgrp_data %>%
  ggplot(aes(x = WT_na,
             y = Sex,
             fill = Sex)) +
  ggtitle("Plot of Distribution of Weight \nby Sex") +
  xlab("Weight (pounds)") +
  scale_fill_discrete(name = "Sex", labels = c("Female", "Male")) +
  ggridges::geom_density_ridges(bandwidth = 4) + theme_ipsum() 


### by Birth Order
HT_BO <- subgrp_data %>%
  ggplot(aes(x = HT_na,
             y = BO,
             fill = BO)) +
  ggtitle("Plot of Distribution of Height \nby Birth Order") +
  xlab("Height (inches)") +
  ylab("Birth Order") +
  scale_fill_discrete(name = "Birth Order", labels = c("Child 1", "Child 2")) +
  ggridges::geom_density_ridges(bandwidth = 4) + theme_ipsum() 


WT_BO <- subgrp_data %>%
  ggplot(aes(x = WT_na,
             y = BO,
             fill = BO)) +
  ggtitle("Plot of Distribution of Weight \nby Birth Order") +
  xlab("Weight (pounds)") +
  ylab("Birth Order") +
  scale_fill_discrete(name = "Birth Order", labels = c("Child 1", "Child 2")) +
  ggridges::geom_density_ridges(bandwidth = 4) + theme_ipsum() 



plot_grid(HT_Sex,WT_Sex,
          HT_BO,WT_BO,
          nrow = 2, ncol = 2)

```

In light of above data visualizations, we can conclude that the distributions of age across both sex and birth order groups are fairly similar and likely not different between both sex and birth order groups. We could also statistically explore this using a suitable Wilcoxon test before performing the main group comparison. 

```{r}
# Mann-Withney U test
## by SEX
subgrp_data %>%
  wilcox_test(HT_na ~ Sex,
              detailed = TRUE) %>%
  glimpse()

subgrp_data %>%
  wilcox_test(WT_na ~ Sex,
              detailed = TRUE) %>%
  glimpse()

# Mann-Withney U test
## by Birth Order
subgrp_data %>%
  wilcox_test(HT_na ~ BO,
              detailed = TRUE) %>%
  glimpse()

subgrp_data %>%
  wilcox_test(WT_na ~ BO,
              detailed = TRUE) %>%
  glimpse()
```

According to the P-values of each test, the test is not significant for neither of groups, Thus, the groups are considered to be not different. 

##### 4.3 Pearson correlation matrix:

```{r}
names(subgrp_data)

for_corr <- subgrp_data |> dplyr::select(BO,Zyg,Sex,Race,AgeMon,
                                         BWOZ,BirLenth_lasso) |>
  mutate_if(is.factor, as.numeric)

corrplot2(
  data = for_corr,
  method = "pearson",
  sig.level = 0.05,
  order = "original",
  diag = FALSE,
  type = "upper",
  tl.srt = 75
)
```

##### 4.4 Univariate Analysis

```{r}
## get the variable list for testing
names(subgrp_data)
variable.list <- colnames(subgrp_data)
variable.list
variable.list <- variable.list[-c(1,8:11,13:16)]

variable.list
## test the model setting, with or without a random effect 
i=6
mod <- as.formula(sprintf("HT_na ~ %s ", variable.list[i]))

# compare a model with no random effects to a model with a random effect 
## with a random effect 
mod.RE = lme(mod,method="ML",na.action=na.omit,
    random = ~1 |IDNO,  control = lmeControl(opt = 'optim'),
                 data = subgrp_data)
## without  a random effect 
mod = lm(mod,subgrp_data)

## AIC test 
bbmle::AICtab(mod.RE,mod) # lower AIC it is considered significantly better than that model.

summary(mod.RE)$tTable 

round(summary(mod.RE)$tTable,3) |> as.data.frame() |> add_column(
  Outcome = noquote("HT"),
  Varible = noquote(variable.list[i]), .before = "Value") |> dplyr::select(-c(`Std.Error`,`DF`,`t-value`)) |>
  dplyr::rename("Estimate" = "Value") |> slice(-1)



######### 
# for loop for table Automation
#########
# create a empty output table to store results
subgrpresult_tab <- data.frame(V1 = character(),
                         V2 = character(),
                         V3 = numeric(),
                         V4 = numeric())
names(subgrpresult_tab)[names(subgrpresult_tab)=='V1']='Outcome'
names(subgrpresult_tab)[names(subgrpresult_tab)=='V2']='Varible'
names(subgrpresult_tab)[names(subgrpresult_tab)=='V3']='Estimate'
names(subgrpresult_tab)[names(subgrpresult_tab)=='V4']='p-Value'
subgrpresult_tab 


# for loop for outcome HT_lasso
for(i in 1:length(variable.list)) {
  # step 1: define model formula
  mod <- as.formula(sprintf("HT_na ~ %s ", variable.list[i])) # %s would be replaced by the variable name, 
  
  # step 2: run model
  mod.RE = lme(mod,method="ML",na.action=na.omit, 
               random = ~1 |IDNO,  control = lmeControl(opt = 'optim'),data = subgrp_data)
  
  # step 3: summarize model result
  fit_result <- round(summary(mod.RE)$tTable,3) |> as.data.frame() |> add_column(
  Outcome = noquote("HT"),
  Varible = noquote(variable.list[i]), .before = "Value") |> dplyr::select(-c(`Std.Error`,`DF`,`t-value`)) |>
  dplyr::rename("Estimate" = "Value") |> slice(-1)

  
  # step 4: append the model result to the final result table
  subgrpresult_tab  <- rbind(subgrpresult_tab,fit_result)
}

# for loop for outcome WT_lasso
for(i in 1:length(variable.list)) {
  # step 1: define model formula
  mod <- as.formula(sprintf("WT_na ~ %s ", variable.list[i])) # %s would be replaced by the variable name, 
  
  # step 2: run model
  mod.RE = lme(mod,method="ML",na.action=na.omit, 
               random = ~1 |IDNO,  control = lmeControl(opt = 'optim'),data = subgrp_data)
  
  # step 3: summarize model result
  fit_result <- round(summary(mod.RE)$tTable,3) |> as.data.frame() |> add_column(
  Outcome = noquote("WT"),
  Varible = noquote(variable.list[i]), .before = "Value") |> dplyr::select(-c(`Std.Error`,`DF`,`t-value`)) |>
  dplyr::rename("Estimate" = "Value") |> slice(-1)

  
  # step 4: append the model result to the final result table
  subgrpresult_tab  <- rbind(subgrpresult_tab,fit_result)
}

# check the final result table

View(subgrpresult_tab)

```


##### 3.4 Multivariate analysis

Model for Height
```{r}

subgrpmod.height1 = lme(HT_na~ Sex + AgeMon + BWOZ  ,method="ML",na.action=na.omit, 
               random = ~1 |IDNO,  control = lmeControl(opt = 'optim'),data = subgrp_data)

subgrpmod.height2 = lme(HT_na ~ Sex + AgeMon + BirLenth_lasso ,method="ML",na.action=na.omit, 
               random = ~1 |IDNO,  control = lmeControl(opt = 'optim'),data = subgrp_data)

subgrpmod.height3 = lme(HT_na ~ Sex + AgeMon + BirLenth_lasso:BWOZ ,method="ML",na.action=na.omit, 
               random = ~1 |IDNO,  control = lmeControl(opt = 'optim'),data = subgrp_data)

  
round(summary(subgrpmod.height1)$tTable,3) 
round(summary(subgrpmod.height2)$tTable,3) 
round(summary(subgrpmod.height3)$tTable,3) 

## AIC test 
bbmle::AICtab(subgrpmod.height1,subgrpmod.height2) 
bbmle::AICtab(subgrpmod.height1,subgrpmod.height3) 
bbmle::AICtab(subgrpmod.height2,subgrpmod.height3) 
```

Model for Weight
```{r}
subgrpmod.weight1 = lme(HT_na~ AgeMon + BWOZ  ,method="ML",na.action=na.omit, 
               random = ~1 |IDNO,  control = lmeControl(opt = 'optim'),data = subgrp_data)

subgrpmod.weight2 = lme(HT_na ~ AgeMon + BirLenth_lasso ,method="ML",na.action=na.omit, 
               random = ~1 |IDNO,  control = lmeControl(opt = 'optim'),data = subgrp_data)

subgrpmod.weight3 = lme(HT_na ~ AgeMon + BirLenth_lasso:BWOZ ,method="ML",na.action=na.omit, 
               random = ~1 |IDNO,  control = lmeControl(opt = 'optim'),data = subgrp_data)

  
round(summary(subgrpmod.weight1)$tTable,3) 
round(summary(subgrpmod.weight2)$tTable,3) 
round(summary(subgrpmod.weight3)$tTable,3) 

## AIC test 
bbmle::AICtab(subgrpmod.weight1,subgrpmod.weight2) 
bbmle::AICtab(subgrpmod.weight1,subgrpmod.weight3) 
bbmle::AICtab(subgrpmod.weight2,subgrpmod.weight3) 

```

## Results {#sec-results}

Describe your results and include relevant tables, plots, and code/comments used to obtain them. You may refer to the @sec-methods as needed. End with a brief conclusion of your findings related to the question you set out to address. You can include references if you'd like, but this is not required.

## Conclusion

This the conclusion. The @sec-results can be invoked if you'd like.
